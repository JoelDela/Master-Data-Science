{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_imdb_reviews_before_class.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "4qz58u5qre3M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Working with text\n",
        "\n",
        "In this problem, we will load movie reviews from IMDB, a famous movie database and website, and we will try to predict whether the review is positive or negative."
      ]
    },
    {
      "metadata": {
        "id": "jOgV26v4re3P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First, the function we will use to diagnose the performance of our model"
      ]
    },
    {
      "metadata": {
        "id": "bP88A3e2re3S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f181e444-b968-4432-dee6-ee1cd5250dc2"
      },
      "cell_type": "code",
      "source": [
        "%pylab inline\n",
        "plt.style.use('seaborn-talk')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0dYZcDDBre3c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_metric(history, metric):\n",
        "    history_dict = history.history\n",
        "    values = history_dict[metric]\n",
        "    if 'val_' + metric in history_dict.keys():  \n",
        "        val_values = history_dict['val_' + metric]\n",
        "\n",
        "    epochs = range(1, len(values) + 1)\n",
        "\n",
        "    if 'val_' + metric in history_dict.keys():  \n",
        "        plt.plot(epochs, val_values, label='Validation')\n",
        "    plt.semilogy(epochs, values, label='Training')\n",
        "\n",
        "    if 'val_' + metric in history_dict.keys():  \n",
        "        plt.title('Training and validation %s' % metric)\n",
        "    else:\n",
        "        plt.title('Training %s' % metric)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel(metric.capitalize())\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    plt.show()  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gj60xTILre3f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Input data"
      ]
    },
    {
      "metadata": {
        "id": "5bGP8TXgre3g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "832fe0c4-9e71-469f-9e8b-592c446ecf3f"
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import imdb"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "LWMsRpYTre3l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Run this to download the data prior to the lecture\n",
        "# Los textos de los user reviews son la entrada. La salida son las estrellas de\n",
        "# la gente\n",
        "train, test = imdb.load_data(num_words=10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YbFhR2T4re3p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00f07819-f0ba-4f13-e39f-b533a384449d"
      },
      "cell_type": "code",
      "source": [
        "type(train)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tuple"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "3vQylg9zre3t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Why are these *texts* numbers?"
      ]
    },
    {
      "metadata": {
        "id": "KnK8MqDusa4g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "36ad4090-7377-4a06-867f-0162f1746eb1"
      },
      "cell_type": "code",
      "source": [
        "train[1].shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "8Yx2Ih46sbTO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a969160-7d23-4386-b4cf-bf9d0aba0a68"
      },
      "cell_type": "code",
      "source": [
        "train[0].shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "LEKMSM5OsbZi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_text, train_labels = train\n",
        "test_text, test_labels = test\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n1AeNW2ysbdr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aaa8d3ee-4ad9-4630-c8c1-55ad9bbb8dda"
      },
      "cell_type": "code",
      "source": [
        "train_text[4][0:10]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 249, 1323, 7, 61, 113, 10, 10, 13, 1637]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "FSfj9H2psbXI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4348254c-fa15-43cf-e8cb-47a98c490da5"
      },
      "cell_type": "code",
      "source": [
        "train_labels[4]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "0RpGi1vksrv-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# estos indices son una lookuptable del diccionario de las palabras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VTH7UDtzsr8J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word_index = imdb.get_word_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TV4tS6ZjssGx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ef7a0b6-d403-4e0c-8f0f-39ad5199cdc9"
      },
      "cell_type": "code",
      "source": [
        "[word_index[i] for i in ['car', 'phone']]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[516, 1696]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "J9Wq9blWre3x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "These are actually indices in a word index"
      ]
    },
    {
      "metadata": {
        "id": "XthgKfi8re35",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reversed_word_index = dict((value, key) for (key, value) in word_index.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ba_wKFjDre3-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_text_from_vector(v):\n",
        "    return ' '.join(reversed_word_index.get(i-3, '?') for i in v)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WFFcZyqUre4D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4387ebd0-9107-4446-b80a-92521338e86c"
      },
      "cell_type": "code",
      "source": [
        "get_text_from_vector(train_text[4][0:10])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'? worst mistake of my life br br i picked'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "QTcfeSu0re4I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Prepare data for the network\n",
        "\n",
        "We need to prepare the data to be an input to the neural network. The input must be a **tensor**. In our case, all vectors should be of the same length. But not all reviews are of the same size, so the vectors will have different sizes. How can we overcome this problem?\n",
        "\n",
        "* We can zero-pad the vectors, so all of them have the same size, and then combine them in a tensor. We would need to add an *Embedding* layer to learn **word embeddings** (more later)\n",
        "* Or we can use 1-HOT encoding\n",
        "\n",
        "In both cases, we will have vectors of size $10^4$ (the maximum number of words). Let's go with the 1-HOT encoding."
      ]
    },
    {
      "metadata": {
        "id": "YZr0TI9Pre4J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import text\n",
        "# Las sequencias son listas en las que el orden importa, como series temporales."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2_2tmtWAuzSJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf43fe70-8b43-476d-d991-a438b1c71a1d"
      },
      "cell_type": "code",
      "source": [
        "train_text.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "v2IHllkCuzY2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9cd3676c-5c2f-4843-ac0c-aa3ab57b65d5"
      },
      "cell_type": "code",
      "source": [
        "type(train_text)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "5CqcE0O8uzWL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e2d679ae-f861-44a3-f5dd-a7b039931bd2"
      },
      "cell_type": "code",
      "source": [
        "len(train_text[2])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "141"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "CrYxO2SauzPX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "86384c16-d924-450a-82e3-bdf293a5a0d9"
      },
      "cell_type": "code",
      "source": [
        "len(train_text[3])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "550"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "U0qrmjPxvAe4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# la lngitud es el numero de palabras que tiene esa review. Necesitamos que todas\n",
        "# las reviews tengan el mismo numero de palabras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R-X3l9vYvA0U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "text.Tokenizer.sequences_to_matrix \n",
        "tokenizer = text.Tokenizer(num_words=10000)\n",
        "# con esto le decimos las palabras máximas que puede tener un tokenizador"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_FhUjbaKvAxc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Los tokenizadores te debiden algo en unidades mas pequeñas. Por ejemplo, frases en palabras.\n",
        "# o verbos a su raiz, o palabras a su raiz (eliminando el genero)\n",
        "\n",
        "train_text_m = tokenizer.sequences_to_matrix (train_text, mode='binary')\n",
        "# el modo binario es one hot encoding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qMAhpM1lvAuh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "60e303fb-db6d-4f1e-f2e6-c1fe33f385cc"
      },
      "cell_type": "code",
      "source": [
        "train_text_m.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 10000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "xBpTXWplvArr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "36185e16-593c-49ed-f033-2f28c6e14d2d"
      },
      "cell_type": "code",
      "source": [
        "# cada fila es un review, cada columna es un one hot encoding, con 0 si no \n",
        "# aparece y 1 si aparece\n",
        "\n",
        "train_text_m[0][0:25]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 0., 1., 1., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "H76yftUzvAo3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# con este enfoque, no sabes la repetición de las palabras, solo si existen o no\n",
        "# existe. Al igual que el orden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OJp0oqAovAmF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8fb32bc6-e000-4c9e-f451-8e25d4050b72"
      },
      "cell_type": "code",
      "source": [
        "train_labels.shape"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "mJOdjCT5vAjO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de086a3f-8754-4f4a-be11-47654398d65c"
      },
      "cell_type": "code",
      "source": [
        "type(train_labels)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "jjqcINoUw-m5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# no hay que transformar las etiquetas porque las dimensiones encajan y ademas ya son valores binarios de review positiva o negativa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VYLtwckfw-tS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# LAs mismas aplicaciones aplicadas al conjunto de training se aplican al de text\n",
        "test_text_m = tokenizer.sequences_to_matrix (test_text, mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UU8Po-hnw-70",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# no hacemos feature engineer, solo transformamos los datos para que encajen en la red\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VQ_bZqk0ut0U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "26NqhS3Nre4L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**EXERCISE 1**. Can you see any problem with this approach? How would you solve it?\n",
        "\n",
        "**EXERCISE 2**. Do we need to transform the labels? Why? Or why not?"
      ]
    },
    {
      "metadata": {
        "id": "bi2hHKb2re4N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Let's build the model"
      ]
    },
    {
      "metadata": {
        "id": "Ave3izZ6re4O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import models, layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iz71QuQSxzS2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Recordar que hay que pasar una tupla a la red\n",
        "# Hay que ir reduciendo las dimensiones de las capas porque la salida es sólo un número\n",
        "m1hot = models.Sequential()\n",
        "m1hot.add(layers.Dense(256, activation='relu', input_shape=(10000,)))\n",
        "m1hot.add(layers.Dense(128, activation='relu'))\n",
        "m1hot.add(layers.Dense(64, activation='relu'))\n",
        "# En la salida la función de activación es muy importante, dado que en este caso\n",
        "# debe estár acotada entre 0 y 1, dado que lo queremos predecir es un valor binario\n",
        "# Es bueno que la función de activación esté relacionada con la de pérdidas. En este caso la distancia esta entre 0 y 1\n",
        "m1hot.add(layers.Dense(1, activation='sigmoid'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TEOq9HTaxzez",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import optimizers, losses, metrics\n",
        "m1hot.compile(\n",
        "optimizer=optimizers.rmsprop(),\n",
        "loss=losses.categorical_crossentropy,\n",
        "metrics=[metrics.binary_accuracy]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XkNTlvK2xzbY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "outputId": "53c5dab5-b77b-45b3-f251-b1270ee9e2a3"
      },
      "cell_type": "code",
      "source": [
        "h = m1hot.fit(train_text_m, train_labels, epochs=20, batch_size=1024, validation_split=.2)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-8e4cffff2970>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm1hot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_text_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1631\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1491\u001b[0m         _check_loss_and_target_compatibility(y,\n\u001b[1;32m   1492\u001b[0m                                              \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_loss_fns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1493\u001b[0;31m                                              self._feed_output_shapes)\n\u001b[0m\u001b[1;32m   1494\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_check_loss_and_target_compatibility\u001b[0;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[1;32m    254\u001b[0m                 raise ValueError(\n\u001b[1;32m    255\u001b[0m                     \u001b[0;34m'You are passing a target array of shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m                     \u001b[0;34m' while using as loss `categorical_crossentropy`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m                     \u001b[0;34m'`categorical_crossentropy` expects '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                     \u001b[0;34m'targets to be binary matrices (1s and 0s) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: You are passing a target array of shape (25000, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via:\n```\nfrom keras.utils import to_categorical\ny_binary = to_categorical(y_int)\n```\n\nAlternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "g3GdabZmxzX1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m1hot.evaluate(test_text_m, test_labels,batch_size=1024)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y9z8SJFCxzPX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9aiB_buBre4S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Analyze performance"
      ]
    },
    {
      "metadata": {
        "id": "JN3X2vE9re4T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lMLGkhbsre4X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We cannot find a satisfactory model with what we have learned so far. Is there any way to have a better representation of text that can provide better results?"
      ]
    },
    {
      "metadata": {
        "id": "VhEGXfb4re4Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AcIicNzvre4c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Word embeddings\n",
        "\n",
        "Using 1-HOT encoded vectors produce large and sparse tensors, that are difficult to learn from using a neural network. Word embeddings are compact vectors, representing words in a vector space. These vectors are learnt in a neural network, with a layer of type *Embedding*. We can also even use pre-trained word embeddings, to improve our model\n",
        "\n",
        "![](./imgs/07_embeddings.png)\n",
        "\n",
        "To generate  an embedding, we need to tokenize the text, transforming words into indices, and then we use these lists of numbers to produce the vectorial representation:\n",
        "\n",
        "![](./imgs/08_embeddings.png)\n",
        "\n",
        "More info:\n",
        "* http://www.offconvex.org/2015/12/12/word-embeddings-1/\n",
        "* http://www.offconvex.org/2016/02/14/word-embeddings-2/"
      ]
    },
    {
      "metadata": {
        "id": "fd21n5kdre4d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Input data for word embeddings"
      ]
    },
    {
      "metadata": {
        "id": "8rgkhGx2re4e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# rey - reina = principe - princesa\n",
        "# rey + mujer = reina\n",
        "# hay tipos de relaciones que se capturan en los embeddings que podemos aprovechar\n",
        "# se captura tanto la secuencia como la semantica. \n",
        "\n",
        "# Igual que hay embedings de palabras, hay embeddings de cualquier cosa. Por ejemplo,\n",
        "# el client to vec, que transforma las propiedades de un cliente a vectores."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mPt9gdZvre4h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Let's build the model with embeddings"
      ]
    },
    {
      "metadata": {
        "id": "BT-e6UmHre4i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bebf7e92-603c-48bd-9cb8-3ff17ad45227"
      },
      "cell_type": "code",
      "source": [
        "train_text.shape"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "metadata": {
        "id": "kbsArs1b3E-R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1154ac59-0f4e-4d1d-c352-0f48428b1861"
      },
      "cell_type": "code",
      "source": [
        "train_labels.shape"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "metadata": {
        "id": "Vodi8HBM3FG7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Se va a decidir un tamaño máximo de los reviews. Los reviews mas cortos los populamos \n",
        "# con zeros y los mas largos los truncamos.\n",
        "\n",
        "# mapear cosas que no existen a zeros es una decisión arbitraria que puede afectar\n",
        "# a la predicción\n",
        "\n",
        "max_len = 100 # los acotamos a 100 xq estos modelos son mas complejos y tarda mas\n",
        "embedding_dim = 32\n",
        "max_word = 1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rpTgWr3v3FVR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import sequence\n",
        "\n",
        "train_text_p = sequence.pad_sequences(train_text, maxlen=max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L4IzXULG3FDn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_text_p = sequence.pad_sequences(test_text, maxlen=max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9kt2S-e25wn7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "47509f15-e998-4527-8cf7-e434a2e1cd19"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 32)          3200      \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, None, 32)          1056      \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, None, 16)          528       \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, None, 1)           17        \n",
            "=================================================================\n",
            "Total params: 4,801\n",
            "Trainable params: 4,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "II1XgqPL4G-X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# cada 100 palabras se va a convertir en un vector de 32 dimensiones\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HqvLVMDj43Ue",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tra"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sP5SDdmd4HRm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# las capas densas son multiplicaciones de matrices, pero no tiene capacidad de estado ni de orden en el que llegan los ejemplos\n",
        "# las redes recurrentes si tienen esa memoria y son capaces de modelar la secuencia. Su memoria es corta (adjetivo/nombre) las captura\n",
        "# pero no mucho mas (por ejemplo parrafos)\n",
        "\n",
        "m2emb = models.Sequential()\n",
        "m2emb.add(layers.Embedding(max_len, embedding_dim))\n",
        "m2emb.add(layers.SimpleRNN(32, return_sequences=True))\n",
        "m2emb.add(layers.SimpleRNN(16, return_sequences=True))\n",
        "m2emb.add(layers.SimpleRNN(8)) # con esto retorna un numero, no una secuencia\n",
        "m2emb.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-zK0k3jQ4HNZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m2emb.compile(\n",
        "  optimizer=optimizers.rmsprop(),\n",
        "  loss=losses.binary_crossentropy,\n",
        "  metrics=[metrics.binary_accuracy]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mUm9YnkX50up",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "6a4756f0-c938-4d7d-a97c-50142ef128cd"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "m2emb.summary()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_12 (Embedding)     (None, None, 32)          3200      \n",
            "_________________________________________________________________\n",
            "simple_rnn_9 (SimpleRNN)     (None, None, 32)          2080      \n",
            "_________________________________________________________________\n",
            "simple_rnn_10 (SimpleRNN)    (None, None, 16)          784       \n",
            "_________________________________________________________________\n",
            "simple_rnn_11 (SimpleRNN)    (None, 8)                 200       \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 6,273\n",
            "Trainable params: 6,273\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pGHBElJm4HI6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        },
        "outputId": "298cf97d-c337-4c58-b690-f03cae37703c"
      },
      "cell_type": "code",
      "source": [
        "h = m2emb.fit(train_text_p, train_labels, epochs=20, batch_size=1024, validation_split=.2)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/20\n",
            "20000/20000 [==============================] - 5s 229us/step - loss: 6.4548 - binary_accuracy: 0.1034 - val_loss: 8.0700 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "20000/20000 [==============================] - 4s 194us/step - loss: 7.9465 - binary_accuracy: 0.0000e+00 - val_loss: 8.0700 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 3/20\n",
            "20000/20000 [==============================] - 4s 194us/step - loss: 7.9465 - binary_accuracy: 0.0000e+00 - val_loss: 8.0700 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 4/20\n",
            "20000/20000 [==============================] - 4s 196us/step - loss: 7.9465 - binary_accuracy: 0.0000e+00 - val_loss: 8.0700 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 5/20\n",
            "20000/20000 [==============================] - 4s 197us/step - loss: 7.9465 - binary_accuracy: 0.0000e+00 - val_loss: 8.0700 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 6/20\n",
            "20000/20000 [==============================] - 4s 194us/step - loss: 7.9465 - binary_accuracy: 0.0000e+00 - val_loss: 8.0700 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 7/20\n",
            "20000/20000 [==============================] - 4s 192us/step - loss: 7.9465 - binary_accuracy: 0.0000e+00 - val_loss: 8.0700 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 8/20\n",
            "20000/20000 [==============================] - 4s 193us/step - loss: 7.9465 - binary_accuracy: 0.0000e+00 - val_loss: 8.0700 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 9/20\n",
            "20000/20000 [==============================] - 4s 194us/step - loss: 7.9465 - binary_accuracy: 0.0000e+00 - val_loss: 8.0700 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 10/20\n",
            "20000/20000 [==============================] - 4s 193us/step - loss: 7.9465 - binary_accuracy: 0.0000e+00 - val_loss: 8.0700 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 11/20\n",
            "20000/20000 [==============================] - 4s 193us/step - loss: 7.9465 - binary_accuracy: 0.0000e+00 - val_loss: 8.0700 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 12/20\n",
            "20000/20000 [==============================] - 4s 195us/step - loss: 7.9465 - binary_accuracy: 0.0000e+00 - val_loss: 8.0700 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 13/20\n",
            "20000/20000 [==============================] - 4s 193us/step - loss: 7.9465 - binary_accuracy: 0.0000e+00 - val_loss: 8.0700 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 14/20\n",
            "20000/20000 [==============================] - 4s 193us/step - loss: 7.9465 - binary_accuracy: 0.0000e+00 - val_loss: 8.0700 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 15/20\n",
            "20000/20000 [==============================] - 4s 194us/step - loss: 7.9465 - binary_accuracy: 0.0000e+00 - val_loss: 8.0700 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 16/20\n",
            "20000/20000 [==============================] - 4s 193us/step - loss: 7.9465 - binary_accuracy: 0.0000e+00 - val_loss: 8.0700 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 17/20\n",
            "20000/20000 [==============================] - 4s 193us/step - loss: 7.9465 - binary_accuracy: 0.0000e+00 - val_loss: 8.0700 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 18/20\n",
            "20000/20000 [==============================] - 4s 194us/step - loss: 7.9465 - binary_accuracy: 0.0000e+00 - val_loss: 8.0700 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 19/20\n",
            "20000/20000 [==============================] - 4s 194us/step - loss: 7.9465 - binary_accuracy: 0.0000e+00 - val_loss: 8.0700 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 20/20\n",
            "20000/20000 [==============================] - 4s 191us/step - loss: 7.9465 - binary_accuracy: 0.0000e+00 - val_loss: 8.0700 - val_binary_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tp2ts6UD4HEz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "outputId": "c12befef-8eed-4b11-eff5-97ca02fcf8df"
      },
      "cell_type": "code",
      "source": [
        "plot_metric(h,'binary_accuracy')"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/ticker.py:2206: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
            "  \"Data has no positive values, and therefore cannot be \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAogAAAHMCAYAAABWaFldAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fb154a40f60>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "urFK-yl_9l1c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "LSTM --> Es todo lo que necesitas !\n",
        "\n",
        "Parece ser que funciona muy bien para muchas cosas"
      ]
    },
    {
      "metadata": {
        "id": "tGPGP2xP9x7H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m2emb = models.Sequential()\n",
        "m2emb.add(layers.Embedding(max_word, embedding_dim))\n",
        "m2emb.add(layers.LSTM(32, return_sequences=True))\n",
        "m2emb.add(layers.LSTM(16))\n",
        "m2emb.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rG3gxwpc-C1W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "6bedb729-89ce-41a6-bc05-bd59512edce0"
      },
      "cell_type": "code",
      "source": [
        "m2emb.summary() # modelo mucho mas complejo que antes"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_15 (Embedding)     (None, None, 32)          32000     \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, None, 32)          8320      \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 16)                3136      \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 43,473\n",
            "Trainable params: 43,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bk3UkaUz9yXz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m2emb.compile(\n",
        "  optimizer=optimizers.rmsprop(),\n",
        "  loss=losses.binary_crossentropy,\n",
        "  metrics=[metrics.binary_accuracy]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LWQm_Cfc9yTo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        },
        "outputId": "14cbd928-238f-42fa-8dd1-6425e87202a2"
      },
      "cell_type": "code",
      "source": [
        "h = m2emb.fit(train_text_p, train_labels, epochs=10, batch_size=1024, validation_split=.2)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/10\n",
            "20000/20000 [==============================] - 12s 593us/step - loss: 7.1885 - binary_accuracy: 0.0499 - val_loss: 8.0700 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "20000/20000 [==============================] - 10s 513us/step - loss: 7.9465 - binary_accuracy: 0.0000e+00 - val_loss: 8.0700 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "20000/20000 [==============================] - 10s 511us/step - loss: 7.9465 - binary_accuracy: 0.0000e+00 - val_loss: 8.0700 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "20000/20000 [==============================] - 10s 514us/step - loss: 7.9465 - binary_accuracy: 0.0000e+00 - val_loss: 8.0700 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "20000/20000 [==============================] - 10s 513us/step - loss: 7.9465 - binary_accuracy: 0.0000e+00 - val_loss: 8.0700 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "20000/20000 [==============================] - 10s 514us/step - loss: 7.9465 - binary_accuracy: 0.0000e+00 - val_loss: 8.0700 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "20000/20000 [==============================] - 10s 512us/step - loss: 7.9465 - binary_accuracy: 0.0000e+00 - val_loss: 8.0700 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "20000/20000 [==============================] - 10s 512us/step - loss: 7.9465 - binary_accuracy: 0.0000e+00 - val_loss: 8.0700 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "20000/20000 [==============================] - 10s 511us/step - loss: 7.9465 - binary_accuracy: 0.0000e+00 - val_loss: 8.0700 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "20000/20000 [==============================] - 10s 514us/step - loss: 7.9465 - binary_accuracy: 0.0000e+00 - val_loss: 8.0700 - val_binary_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uf3WeMhD9yPY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "outputId": "983f6003-fdfb-496c-b5a4-eff806fa3682"
      },
      "cell_type": "code",
      "source": [
        "plot_metric(h,'binary_accuracy')"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/ticker.py:2206: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
            "  \"Data has no positive values, and therefore cannot be \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAogAAAHMCAYAAABWaFldAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fb14b290128>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Eof4XWw49yLA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m2emb.evaluate(text_text_p, )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cKoZqLGh9yG6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ev5s3Qvj9yC2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mkOufmN7re4k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Analyze performance"
      ]
    },
    {
      "metadata": {
        "id": "4cetoCIFre4l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Not bad, with just an embedding layer, we get $75\\%$ accuracy"
      ]
    },
    {
      "metadata": {
        "id": "9FVZsquHre4l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qf9F49N5re4o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "How many reviews will be misclassified?"
      ]
    },
    {
      "metadata": {
        "id": "6HUyW5nTre4p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u2CoXDSFre4r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's check some of the predictions"
      ]
    },
    {
      "metadata": {
        "id": "rG82rOl8re4s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "N = 123\n",
        "# N = 2344"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ue-bwtZpre4u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jShNXTogre4w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "So this prediction is correct. It says the review is negative. Let's have a look at the text:"
      ]
    },
    {
      "metadata": {
        "id": "6cJWq_8Vre4x",
        "colab_type": "code",
        "colab": {},
        "outputId": "0ed1ac36-02a4-49f6-a241-5c7c1b004ba5"
      },
      "cell_type": "code",
      "source": [
        "get_text_from_vector(test_text[N])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"? if you believe that any given war movie can make you really feel the war you need to see called the ? are flying in english it tells the story of ? ? and boris who are in love on the verge of wwii they are walking along the ? watching the ? fly by when the war starts boris is promptly sent off to war ? hides out with a family and ends up marrying the son whom she does not love boris meanwhile continues ? through the countryside fighting the nazis and experiencing all the horrors of war until he he runs out of energy when ? working in a military hospital receives this news she refuses to accept it until ? body arrives home on one of the trains simultaneously the radio ? that germany has ? and the allied powers have won the war the soviet union lost 27 million citizens but it's the start of a new era br br this movie did a very good job showing the human impact of the war not only in the battlefield but also how it affected the ? population this is definitely a movie that everyone should see\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "weZg46XSre42",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Can we find all the reviews that are wrongly classified?"
      ]
    },
    {
      "metadata": {
        "id": "-wTMQfihre43",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "me6hv3sYre46",
        "colab_type": "code",
        "colab": {},
        "outputId": "1e97b24f-02a9-409f-c9bf-8dd277363987"
      },
      "cell_type": "code",
      "source": [
        "get_text_from_vector(test_text[3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"? i generally love this type of movie however this time i found myself wanting to kick the screen since i can't do that i will just complain about it this was absolutely idiotic the things that happen with the dead kids are very cool but the alive people are absolute idiots i am a grown man pretty big and i can defend myself well however i would not do half the stuff the little girl does in this movie also the mother in this movie is reckless with her children to the point of neglect i wish i wasn't so angry about her and her actions because i would have otherwise enjoyed the flick what a number she was take my advise and fast forward through everything you see her do until the end also is anyone else getting sick of watching movies that are filmed so dark anymore one can hardly see what is being filmed as an audience we are ? involved with the actions on the screen so then why the hell can't we have night vision\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "metadata": {
        "id": "FkKsZArcre4-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Is the classifier symmetric?"
      ]
    },
    {
      "metadata": {
        "id": "z751yhoFre4-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AMoFIO9ure5A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**EXERCISE** Can you construct the confusion matrix for this model? Can you calculate the precision and recall? How does it compare to accuracy?\n",
        "* See https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/\n",
        "\n",
        "**EXERCISE (more complex)** Keras decided some time ago to remove precision, recall and F1-score from the list of available metrics. Was it a good decision? Why? Why did the Keras' authors did not remove accuracy too?\n",
        "* https://github.com/keras-team/keras/issues/5794\n",
        "* https://github.com/keras-team/keras/issues/4592\n",
        "\n",
        "**EXERCISE** What is the ROC curve? Could you build the ROC curve for this model? How would you use a ROC curve to evaluate a classifier?\n",
        "* https://en.wikipedia.org/wiki/Receiver_operating_characteristic\n",
        "* Help: https://stackoverflow.com/questions/25009284/how-to-plot-roc-curve-in-python"
      ]
    },
    {
      "metadata": {
        "id": "2sNzCyHlre5B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f1MD2kp8re5D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's analyze wrong positives and wrong negatives separately. Then we will try to find a relationship between the words and the misclassification, both for false positives and negatives."
      ]
    },
    {
      "metadata": {
        "id": "TMFbytF9re5E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rBp0-o9Ire5F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now let's compare with the words of the true positives"
      ]
    },
    {
      "metadata": {
        "id": "AA3DSDYgre5G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FagGHfEvre5I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "So the most common words are very similar. Not surprising. Let's calculate the relative frequency of each word, and then find what are the words with the highest difference in relative frequency."
      ]
    },
    {
      "metadata": {
        "id": "OJs1twGwre5I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JAqTX3Ofre5K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We see words such as *great*, *best*, *excellent*, which have a large difference between the true and the false positives. So false positives seem to lack some extreme words, and the classifier is having a hard time trying to assign a category to those reviews."
      ]
    },
    {
      "metadata": {
        "id": "6ASygtpQre5L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}