{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with Tensorflow\n",
    "\n",
    "Tensorflow (TF) can not only be used for deep learning, but for numerical computations in general. It is specially suited for handling matrices and tensors.\n",
    "\n",
    "In this notebook we will explore how to use TF for *traditional* machine learning (ML) model, and how it compares to solving the same problem using a deep learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "1.11.0\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "plt.style.use('seaborn-talk')\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting familiar with Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF uses lazy evaluation. When we define an operation, we only create the execution graph for that operation. We need to explicitly *run* the graph to obtain the result.\n",
    "* TF also supports eager execution in Python, which runs the operations inmediately, but we will not use it in this notebook\n",
    "* Eager execution is intented for running small tests in an interactive notebook or prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Numpy, operations occur as soon as they are written.\n",
    "However, in TF we need to explicitly run the graph to obtain a result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(5)\n",
    "y = tf.constant(6)\n",
    "z = tf.multiply(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const_3:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    z_ = sess.run(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "To obtain the area of a triangle given the length of its sides $a$, $b$ and $c$, you can use the Formula of Heron \n",
    "\n",
    "$\\sqrt{s(s-a)(s-b)(s-c)}$ where $\\displaystyle s=\\frac{a+b+c}{2}$ \n",
    "\n",
    "* For more context, see https://en.wikipedia.org/wiki/Heron%27s_formula\n",
    "\n",
    "Assume that $a$, $b$ and $c$ are given as an array with 3 columns and an arbirtray number of rows, named *sides*. Each row is a possible triangle\n",
    "\n",
    "You should write two functions that takes as inputs the arrays *sides* and returns an array with as many components as triangles, being each component the area of the corresponding triangle:\n",
    "* One function using Numpy\n",
    "* One function using Tensorflow. \n",
    " *  The function should return the *tf.Tensor* without running it. The caller of the function will need to run the output afterwards to get the result\n",
    " * How do you do a square root in TF? Look up the available operations at https://www.tensorflow.org/api_docs/python/tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Solution with Numpy\n",
    "def heron_np(sides):\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check results with numpy\n",
    "sides = np.array([[5, 3, 7.1],[ 2.3, 4.1, 4.8]])\n",
    "print(\"Input triangles:\")\n",
    "print(sides)\n",
    "\n",
    "print(\"Output with multiple rows:\")\n",
    "multi = heron_np(sides)\n",
    "print(multi)\n",
    "print(\"Outputs with single rows:\")\n",
    "a1 = heron_np(np.array([sides[0,:]]))\n",
    "a2 = heron_np(np.array([sides[1,:]]))\n",
    "print(a1)\n",
    "print(a2)\n",
    "assert np.all(multi == np.append(a1,a2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Solution with TF: handling tensors in TF is quite similar to handling numpy arrays\n",
    "def heron_tf(sides):\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check the TF solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our first model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this model, we will use the following data:\n",
    "* http://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml\n",
    "\n",
    "In the data subdirectory, you will find three files. We have divided the dataset in three subsets\n",
    "* Training\n",
    "* Validation\n",
    "* Test\n",
    "\n",
    "**Question**: Why three different sets? What will we use the validation set for? Could not we use just two subsets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 juan juan  84K nov  4 01:52 ../data/taxi-test.csv\r\n",
      "-rw-rw-r-- 1 juan juan 394K nov  4 01:52 ../data/taxi-train.csv\r\n",
      "-rw-rw-r-- 1 juan juan  84K nov  4 01:52 ../data/taxi-valid.csv\r\n"
     ]
    }
   ],
   "source": [
    "! ls -hl ../data/taxi*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will use Pandas to explore the data\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The CSV files come without a header, let's put some names for clarity\n",
    "CSV_COLUMNS = ['fare_amount', 'pickuplon','pickuplat','dropofflon','dropofflat','passengers', 'key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the train, validation and test data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming input data\n",
    "We will train a simple linear model using tf.estimator, a higher level API of TF.\n",
    "\n",
    "Notice that we have the data in Pandas dataframes. How can we feed a pandas dataframe to TF?\n",
    "\n",
    "One option is converting it to tensor from the dataframe using `tf.convert_to_tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert train, validation and test pd dataframes to tensors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it is easier to keep the Pandas df info (column names, etc.) to evaluate the model later on. We can create a TF dataset from Pandas, to use with tf.estimator.\n",
    "\n",
    "We will write a function so we can make several tests changing the number of epochs (one of the hyperaparemeters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use tf.estimator.inputs.pandas_input_fn to create a TF dataset from Pandas\n",
    "def pandas2tf(df, epochs):\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_train = pandas2tf(df_train, 1)\n",
    "tf_valid = pandas2tf(df_valid, 1)\n",
    "tf_test = pandas2tf(df_test, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature columns\n",
    "\n",
    "For the model, we need to select the feature columns. We will use all columns, except the *key* one, which is just an index.\n",
    "\n",
    "Also, the first column is in fact the target variable that we will predict, so we will remove it from the features too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature_cols using tf.feature_column.numeric_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "import shutil\n",
    "# WARNING!!!! THIS DIRECTORY WILL BE REMOVED, DON'T PUT ANYTHING THERE\n",
    "OUTDIR = 'taxi_trained'\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression model using tf.estimator.LinearRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model\n",
    "\n",
    "Is this model good? How can we interpret the average loss in the evaluation metrics dict? What's the *physical meaning* of that number?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the model with the help of the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question\n",
    "\n",
    "What is the average loss if we use the tf_train with evaluate? Is it correct to use those numbers to evaluate the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: plot the average loss for the training and validation datasets, over the num. of epochs\n",
    "\n",
    "What is the impact of the number of epochs in the results of the model?\n",
    "\n",
    "Repeat the training process with epochs ranging from 1 to 10, and plot the *average_loss* for the training and validation datasets.\n",
    "* What conclusions can you extract from that plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "OUTDIR = 'taxi_trained'\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "    \n",
    "def train_for_epochs(nepochs):\n",
    "    return #train_loss, valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "epochs = np.arange(1,11)\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "for e in epochs:\n",
    "    print(\"Training with %d epochs...\" % e)\n",
    "    t, v = train_for_epochs(e)\n",
    "    train_loss.append(t)\n",
    "    valid_loss.append(v)\n",
    "    \n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(epochs, train_loss, label='Training')\n",
    "plt.plot(epochs, valid_loss, label='Validation')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the model does not look exceptionally good. This is normal, we have just tried a linear model without any kind of feature engineering or transformation; we don't know for instance if the relationship between *fare_amount* and the rest of features is linear or not.\n",
    "\n",
    "Let's try another simple model using TF, but this one will be more complex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A more complex model\n",
    "\n",
    "We are going to reuse a lot of code from the previous model, we will just change the kind of estimator we are using.\n",
    "\n",
    "Let's repeat the same estimator again, and we will run it for 20 epochs this time. Then we will compare it with the new one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this new model better? Why does not the linear model change with the number of epochs?\n",
    "\n",
    "What would you do next to improve the Deep Learning model?\n",
    "* Possible answers: increase the number of epochs, maybe try a more complex model. Any other hyperparam?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with 150 epochs, and see if we can beat the training and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final decision about the models\n",
    "\n",
    "So far, we have been ignoring the test set. We have used the validation dataset to change the hyperparameters of the model. It is now the turn to use the test set to finally decide which model is better: the linear regressor or the neural network.\n",
    "\n",
    "For this, we can retrain the models using both the train and validation sets, with the hyperparameters that we have already decided. Then we will evaluate both models using only the test set, and we will find out which one is better predicting the test set, that is, a set of data that has not been used in any way to tune the model (the validation set has been used to tune the hyperparams, so somehow the validation set info is already included in the model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the LinearRegressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate tf.estimator.DNNRegressor model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ks_dl_course]",
   "language": "python",
   "name": "conda-env-ks_dl_course-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
