{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "plt.style.use('seaborn-talk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this function to plot the metrics of our training process, to help in choosing the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(history, metric):\n",
    "    history_dict = history.history\n",
    "    values = history_dict[metric]\n",
    "    if 'val_' + metric in history_dict.keys():  \n",
    "        val_values = history_dict['val_' + metric]\n",
    "\n",
    "    epochs = range(1, len(values) + 1)\n",
    "\n",
    "    if 'val_' + metric in history_dict.keys():  \n",
    "        plt.plot(epochs, val_values, label='Validation')\n",
    "    plt.semilogy(epochs, values, label='Training')\n",
    "\n",
    "    if 'val_' + metric in history_dict.keys():  \n",
    "        plt.title('Training and validation %s' % metric)\n",
    "    else:\n",
    "        plt.title('Training %s' % metric)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(metric.capitalize())\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this function to explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mnist_image(N, imgs, labels):\n",
    "    print(\"The image below should show the number %d\" % labels[N])\n",
    "    plt.imshow(imgs[N,], cmap=plt.cm.binary)\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The problem\n",
    "\n",
    "We will recognize handwritten digits. For an image containing a number between 0 and 9, we will recognize the number and will produce an int as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load minst images using the method `load_data()`. Be carefull, as it returns a tuple with the image and the lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A note on the curse of dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a similarity measure. For instance, the [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity), that is 1 if vectors are parallel (most similar), and zero if they are perpendicular (lack of correlation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "def cosine_similarity(img1, img2):\n",
    "    # reshape input matrices as vectors\n",
    "    img1_ = img1.reshape((28*28,))\n",
    "    img2_ = img2.reshape((28*28,))\n",
    "    # normalize input vectors\n",
    "    norm1 = np.sqrt(np.sum(img1_*img1_))\n",
    "    norm2 = np.sqrt(np.sum(img2_*img2_))\n",
    "    img1_ = img1_ / norm1\n",
    "    img2_ = img2_ / norm2\n",
    "    sim = 1 - spatial.distance.cosine(img1_, img2_)    \n",
    "    return sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the similarity among two random images, and plot them. Does it make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the similarity among images of numbers 5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the similarity between 5 and 4, or 5 and 8, for instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "As the dimension of our input increases, everything starts looking the same. Distances in high dimensions cannot be used! This is a consequence of the curse of dimensionality.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will design a network that will be able to recognize the number shown at the image (for all the images in the test set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transform\n",
    "\n",
    "We need to change the shape of the data, so it can be fed to the network more easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the min, max, meand and std of training images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the images are 28x28 matrices, with values between 0 and 255. Let's normalize the images, to avoid problems in the numerical computations using large numbers.\n",
    "\n",
    "We will convert the matrix to a vector with 28x28 components, stacking columns on top of each other. This will make the design of the network.\n",
    "* Alternatively, we could add a `Flatten(input_shape=(28,28))` layer to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize image's values to the maximum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we want to assign a *category* to each image, we need to transform the output to categorical format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, our target data is just a set of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to transform it to **1-HOT encoding format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_t = to_categorical(<fill in>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to repeat the same process with the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    <fill in>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will make some decisions about how to train our model.\n",
    "\n",
    "The **objective function**, called also the **loss function** in Machine Learning, will be *categorical crossentropy*. This is because we are trying to predict discrete classes. If we choose a different function, the solution will be different (take a look at [Keras available losses](https://keras.io/losses/)). This is the function that will tell us when we have found the *solution*. Different functions will point to different *solutions*. The categorical crossentropy for a single observation (exmaple in train, for instance) is defined as:\n",
    "\n",
    "$$-\\sum_{{\\rm category} = 1}^M y_{\\rm category} \\log(\\hat{y}_{\\rm category}).$$\n",
    "\n",
    "Have a look at this [cheatsheet](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html).\n",
    "\n",
    "The **optimizer** is the method that we will use to find the minimum of the **loss function**. In general, we will not find the global minimum of the loss function, but a minimum that is good enough. *RMSProp* is one the variants of gradient descent. But there are many more [availbale in Keras](https://keras.io/optimizers/). We will deep dive into the optimization problem later in this course. \n",
    " \n",
    "These two settings will define the family of solutions we will find during the training process.\n",
    "\n",
    "The other parameter, the **metrics**, is only for information purposes. In each step of the training (called **epoch**), Keras will report the value of the metrics. But whether we choose one metric or another will not influence the training process. It is only for reporting how the training is going. That information will be useful for the validation of the model, that is, for the **hyperparameters tuning**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the summary\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's fit the neural network. We will keep the results in a *history* object to plot some parameters after the training, and use that information for improving our model (changing layers, activation functions, etc). This process is called **hyperparameters tuning** or hypeparameters search.\n",
    "\n",
    "Here we need to set two parameters: the number of **epochs** and the **batch size**.\n",
    "\n",
    "In previous cells, I have said that the training process is an optimization problem: we try to find the minimum.\n",
    "\n",
    "That's actually not entirely true. In practice, we don't keep searching for a minimum. Instead, we train for a preset number of epochs. Then we analyze the output using the validation set. If we detect overfit, then we reduce the number of epochs. If we don't detect it, then maybe we can keep going for some more epochs to find a better model. The number of epochs is another hyperparameter. In general, we should stop the training as early as possible. Any further epoch can make our model overfit, and therefore generalize poorly.\n",
    "\n",
    "The batch size is another hyperparameter. The network is not updated item by item, vector by vector. We can actually calculate the weights for a batch of several items, forming a matrix or a tensor. The batch size will affect the granularity of the calculations and the performance. A larger batch size will probably result in a slightly worse accuracy, but in a better performance. As long as the batch size is not so huge that it cannot be kept in memory. Because we are running on a GPU, it is a good idea to use a power of 2 for the batch size. It will probably make a better use of the GPU. But again, the effect of the batch size must be tested using the validation set, and adjusted until we find a good value for that parameter.\n",
    "\n",
    "An epoch is a full pass over the training dataset. At the end of each epoch, Keras will calculate the value of the metrics for the training set, and the loss function and metrics for the validation set. The loss and metrics of the validation set are useful for the hyperparameters tuning process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train!\n",
    "h = <fill in>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(h, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(h, 'categorical_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now let's check how well the model works with the test dataset. Remember that we don't have used it at all during the training and tuning of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the classification performance\n",
    "\n",
    "For this, we will use the model's `evaluation` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = m.evaluate(<test images>, <test labels>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how well it predicts some random items from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a random image \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction is a 10-element vector (*1-HOT encoded vector*), with (something like) the probability of each class. The location of the max is giving us the predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the prediction of that same image. This process is what it's called **inference**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(<your prediciton>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "**EXERCISE 1**: Change the [activation function](https://keras.io/activations/) in the model. How does it affect accuracy? What happens if you use linear activation function? What happens if we use the $\\tanh$ function? Does it affect to overfitting?\n",
    "\n",
    " \n",
    "Here we see that the accuracy keeps increasing over epochs. An overfitted model would produce a decrease of the validation accuracy at some point. This means that we have found an optimal model. The validation loss is stuck at a minimum, but the accuracy is not affected by the extra epochs.\n",
    "\n",
    "_**EXERCISE 2**_: How is the model accuracy affected if we start over and fit for 40 epochs? And for 4? And for 400?\n",
    "\n",
    "_**EXERCISE 4**_: What is the most simple model that you can get that achieves a similar validation performance (accuracy)? (Note that the loss values might not be comparable if we use regularization techniques, change the network architecture, etc.)\n",
    "\n",
    "_**EXERCISE 5**_: Can you find a test item that is predicted wrongly? How many images are predicted wrongly? Can you find all the items that are wrongly classified? \n",
    "\n",
    "_**EXERCISE 6**_: Some digits are more difficult to recognize than others. Because we know the test labels, we can find out how many times the corresponding test images are misclassified. Could you find what are the top 3 test labels that are more often misclassified?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ks_dl_course]",
   "language": "python",
   "name": "conda-env-ks_dl_course-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
